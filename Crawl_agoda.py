# -*- coding: utf-8 -*-
"""Crawl agoda.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hAovxoCUzBK1kuVB9EYlMCuArTCHkun4
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
import time
import csv
from bs4 import BeautifulSoup

# "Use the Service object to specify the driver."
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)

# Access Agoda
url = 'https://www.agoda.com/'
driver.get(url)
print('Đã truy cập vào URL thành công: ', url)


time.sleep(5)

# Find and Click Search button
search_field = driver.find_element(By.XPATH, '//*[@id="textInput"]')
search_field.click()
time.sleep(3)
# Choos DaNang
search_field_DaNang = driver.find_element(By.XPATH, '//*[@id="FocusTrap"]/div/div/div[1]/div/div/div/div[2]/div/div[5]')
search_field_DaNang.click()
print('Đã chọn thành phố Đà Nẵng')
time.sleep(3)

# Turn off date button
cancel = driver.find_element(By.XPATH, '//*[@id="check-in-box"]')
cancel.click()
print('Đã hủy chọn ngày')
time.sleep(3)


search_button = driver.find_element(By.XPATH, '//*[@id="Tabs-Container"]/button')
search_button.click()
print('Đã nhấn nút tìm kiếm')


time.sleep(5)

# Close old page and open new one
tabs = driver.window_handles
driver.close()
print('Đã đóng tab cũ')
driver.switch_to.window(tabs[1])
print('Đã chuyển sang tab mới')
time.sleep(5)
# "Main loop: Scroll the page, collect links, and click the 'Next' button."
hotel_links = []

while True:
    scroll_pause_time = 2
    scroll_increment = 1000
    current_position = 0
    last_height = driver.execute_script("return document.body.scrollHeight")

    while True:
        driver.execute_script(f"window.scrollBy(0, {scroll_increment});")
        current_position += scroll_increment
        time.sleep(scroll_pause_time)

        new_height = driver.execute_script("return document.body.scrollHeight")
        if current_position >= new_height:
            print('Đã cuộn hết trang.')
            break

    # Get HTML
    time.sleep(5)
    page_source = driver.page_source
    soup = BeautifulSoup(page_source, 'html.parser')
#Find tags h3 with link
    for infor_div in soup.find_all('li', class_='PropertyCard PropertyCardItem'):
        a_tag = infor_div.find('a', href=True)
        if a_tag:
            hotel_links.append(a_tag['href'])

    print(f'Tìm thấy {len(hotel_links)} liên kết khách sạn.')

    # Find Next button
    try:
        next_button = driver.find_element(By.XPATH, '//*[@id="paginationNext"]')
        next_button.click()
        print('Đã nhấn nút Next')
        time.sleep(5)
    except Exception as e:
        print("Không tìm thấy nút 'Next', đã đến trang cuối.")
        break

# Create file
with open('hotel_reviews_agoda.csv', mode='a', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Hotel URL', 'Score', 'Total Reviews', 'Reviews', 'Service', 'Location', 'Facilities', 'Cleanliness', 'Value for money'])

    # Access all link
    for idx, link in enumerate(hotel_links, 1):
        hotel_url = 'https://www.agoda.com' + link
        print(f'[{idx}/{len(hotel_links)}] Đang truy cập trang khách sạn: {hotel_url}')
        driver.get(hotel_url)
        time.sleep(5)

        # Get HTML
        page_source_review = driver.page_source
        soup_review = BeautifulSoup(page_source_review, 'html.parser')
        review_button= driver.find_element(By.XPATH,'//*[@id="hotelNavBar"]/div/ul/li[5]')
        review_button.click()
        time.sleep(3)
        # Find and get catefory
        if soup_review.find('span', class_='Review__ReviewFormattedScore'):
            score = soup_review.find('span', class_='Review__ReviewFormattedScore').text.strip().split()[-1]
        elif soup_review.find('div', class_='ReviewScore-Number ReviewScore-Number--line-height'):
            score = soup_review.find('div', class_='ReviewScore-Number ReviewScore-Number--line-height').text.strip().split()[-1]
        else:
            score = 'N/A'
        reviews_num = soup_review.find('span', class_='text').text.strip() if soup_review.find('span', class_='text') else 'N/A'
        reviews = soup_review.find('p', class_='af4c3-af4c3-box').text.strip() if soup_review.find('p', class_='af4c3-af4c3-box') else 'N/A'

        # Dictionary to save
        categories = {'Service': 'N/A', 'Cleanliness': 'N/A', 'Location': 'N/A', 'Value for money': 'N/A', 'Facilities': 'N/A'}
        rating_items = soup_review.find_all('div', class_='Review-travelerGrade')
    for item in rating_items:
        #FInd title
        title_span = item.find('span', class_='Review-travelerGradeCategory')
        # Find Score
        score_span = item.find('span', class_='Review-travelerGradeScore')
        if title_span and score_span:
            title_text = title_span.text.strip()
            score_text = score_span.text.strip()
            # Check
            if title_text in categories:
                categories[title_text] = score_text

            if title_span and score_span:
                title_text = title_span.text.strip()
                score_text = score_span.text.strip()
                if title_text in categories:
                    categories[title_text] = score_text

        # Write
        writer.writerow([
            hotel_url,
            score,
            reviews_num,
            reviews,
            categories['Service'],
            categories['Location'],
            categories['Facilities'],
            categories['Cleanliness'],
            categories['Value for money']
        ])
        print(f'Đã ghi thông tin khách sạn vào CSV. Chuyển sang khách sạn tiếp theo...')
        time.sleep(5)

#Close
driver.quit()
print('Đã hoàn thành quá trình cào dữ liệu.')