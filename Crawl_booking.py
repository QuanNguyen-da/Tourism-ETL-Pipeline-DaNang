# -*- coding: utf-8 -*-
"""Crawl-booking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UsAOhcLtv3mTvgc8IgL35t9gC5eFwTKx
"""

pip install selenium

pip install python-time

pip install webdriver-manager

pip install beautifulsoup4

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import csv
from bs4 import BeautifulSoup

## Using Service to specify the driver
service = Service(ChromeDriverManager().install())

driver = webdriver.Chrome(service=service)


url = 'https://www.booking.com/searchresults.html?ss=Da+Nang%2C+Vietnam'

driver.get(url)
print('Đã truy cập vào URL thành công: ', url)

# Wait 5s
time.sleep(5)

# Turn off Login button
try:
    cancel = driver.find_element(By.XPATH, '//*[@id="b2searchresultsPage"]/div[25]/div/div/div/div[1]/div[1]/div/button')
    cancel.click()
    print('Đã tắt popup login nếu có')
except:
    print('Không tìm thấy popup login hoặc đã tắt rồi')

# "Scroll to the bottom of the page to load more content and click the 'Load More' button if it appears."
last_height = driver.execute_script("return document.body.scrollHeight")
while True:
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(8)
    try:
        load_more_button = driver.find_element(By.CSS_SELECTOR, "button.a83ed08757.c21c56c305.bf0537ecb5.f671049264.af7297d90d.c0e0affd09")
        driver.execute_script("arguments[0].scrollIntoView();", load_more_button)
        load_more_button.click()
        print('Đã bấm nút Load More để tải thêm nội dung')
    except:
        print('Không tìm thấy nút Load More hoặc nút không khả dụng')
        time.sleep(5)

    new_height = driver.execute_script("return document.body.scrollHeight")
    if new_height == last_height:
        print('Đã tải xong toàn bộ nội dung của trang')
        break
    last_height = new_height

# Get HTML
time.sleep(5)
page_source = driver.page_source

# Using  BeautifulSoup to analyzes HTML
soup = BeautifulSoup(page_source, 'html.parser')

# Find all tag h3 have link
hotel_links = []
for infor_div in soup.find_all('h3', class_='aab71f8e4e'):
    a_tag = infor_div.find('a', href=True)
    if a_tag:
        hotel_links.append(a_tag['href'])

print(f'Tìm thấy {len(hotel_links)} liên kết khách sạn để cào dữ liệu.')

# Creating Csv and save
with open('hotel_reviews.csv', mode='a', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Hotel URL', 'Score', 'Total Reviews', 'Reviews', 'Address', 'Staff', 'Facilities', 'Cleanliness', 'Comfort', 'Value for money', 'Location', 'Free WiFi'])  # Ghi tiêu đề

    # Access link
    for idx, link in enumerate(hotel_links, 1):
        hotel_url = link
        print(f'[{idx}/{len(hotel_links)}] Đang truy cập trang khách sạn: {hotel_url}')
        driver.get(hotel_url)
        time.sleep(5)

        # Get HTML after Guest Review
        page_source_review = driver.page_source
        soup_review = BeautifulSoup(page_source_review, 'html.parser')

        # find and export some data
        score = soup_review.find('div', class_='a3b8729ab1 d86cee9b25').text.strip().split()[-1] if soup_review.find('div', class_='a3b8729ab1 d86cee9b25') else 'N/A'
        reviews_num = soup_review.find('div', class_='abf093bdfe f45d8e4c32 d935416c47').text.strip() if soup_review.find('div', class_='abf093bdfe f45d8e4c32 d935416c47') else 'N/A'
        Reviews = soup_review.find('div', class_='a3b8729ab1 e6208ee469 cb2cbb3ccb').text.strip() if soup_review.find('div', class_='a3b8729ab1 e6208ee469 cb2cbb3ccb') else 'N/A'

        # Using Selenium và XPath to get Address
        try:
            # Using WebDriverWait to make sure some object loaded
            address_element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.XPATH, "//*[@id='showMap2']/span[1]"))
            )
            address = address_element.text.strip()
        except:
            address = 'N/A'

        # Dictionary
        categories = {
            'Staff': 'N/A',
            'Facilities': 'N/A',
            'Cleanliness': 'N/A',
            'Comfort': 'N/A',
            'Value for money': 'N/A',
            'Location': 'N/A',
            'Free WiFi': 'N/A'
        }

        # **Find review categories**
        rating_categories = soup_review.find_all('div', {'data-testid': 'review-subscore'})
        if rating_categories:
            for rating_category in rating_categories:
                title = rating_category.find('span', class_='be887614c2')
                score_category = rating_category.find('div', class_='bdc1ea4a28')
                if title and score_category:
                    title_text = title.text.strip()
                    score_text = score_category.text.strip()
                    if title_text in categories:
                        categories[title_text] = score_text

        # Write hotel information and categories into a CSV file
        writer.writerow([
            hotel_url,
            score,
            reviews_num,
            Reviews,
            address,
            categories['Staff'],
            categories['Facilities'],
            categories['Cleanliness'],
            categories['Comfort'],
            categories['Value for money'],
            categories['Location'],
            categories['Free WiFi']
        ])

        print(f'Đã ghi thông tin khách sạn vào CSV. Chuyển sang khách sạn tiếp theo...')
        time.sleep(5)

# Close
driver.quit()
print('Hoàn thành quá trình cào dữ liệu. Đã đóng trình duyệt.')